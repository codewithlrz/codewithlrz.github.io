[{"title":"图深度学习笔记-图论基础","url":"/2021/11/24/book-mayao-02-md/","content":" 1 图的表示\n 1.1 图的定义\n一个图（Graph）可以表示为G={V,ε}G = { \\{V,\\varepsilon \\}}G={V,ε}，其中VVV = {v1v_1v1​,⋯\\cdots⋯,vNv_NvN​}是大小为NNN = |VVV|的节点集合，ε\\varepsilonε={ e1e_1e1​,⋯\\cdots⋯,eMe_MeM​}是大小为MMM的边的集合。\n\n如上图（图1），为一个有五个节点和六条边的图。其中{ v1v_1v1​,⋯\\cdots⋯,v5v_5v5​}为五个节点，{ e1e_1e1​,⋯\\cdots⋯,e6e_6e6​}为六条边。\n在图中，如果有一条边eie_iei​连接两个节点vei1v_{e_i}^1vei​1​和vei2v_{e_i}^2vei​2​，那么这条边可以表示为（vei1v_{e_i}^1vei​1​,vei2v_{e_i}^2vei​2​），在有向图中表示边从起点vei1v_{e_i}^1vei​1​指向终点vei2v_{e_i}^2vei​2​。相反在无向图中由于没有顺序之分，则eie_iei​ = （vei1v_{e_i}^1vei​1​,vei2v_{e_i}^2vei​2​）= （vei2v_{e_i}^2vei​2​,vei1v_{e_i}^1vei​1​）。举个例子，如图一中的边e6e_6e6​连接节点v1v_1v1​与节点v5v_5v5​，那么由于图1为无向图，则e6e_6e6​也可以表示为（v1v_1v1​,v5v_5v5​）或（v5v_5v5​,v1v_1v1​）。\n 1.2 邻接矩阵（Adjacency Matrix）\n为了方便查看节点之间的连接关系，图G={V,ε}G = { \\{V,\\varepsilon \\}}G={V,ε}可以等价的表示为邻接矩阵的形式，更加直观的描述节点之间的关系。\n定义: \\textbf{定义: }定义: 给定一个图G={V,ε}G = { \\{V,\\varepsilon \\}}G={V,ε},对应的邻接矩阵可以表示为A∈{0,1}N×NA∈{ \\{ 0,1 \\} ^ { N×N } }A∈{0,1}N×N。邻接矩阵AAA的第iii行第jjj列元素Ai,jA_{i,j}Ai,j​表示节点viv_ivi​和vjv_jvj​的连接关系。具体来讲，如果viv_ivi​与vjv_jvj​相邻，则Ai,j=1A_{i,j} = 1Ai,j​=1，否则Ai,j=0A_{i,j} = 0Ai,j​=0。\n","categories":["图深度学习教材笔记"],"tags":["笔记","GNN","教材"]},{"title":"paper-aGentleIntroductionToGNN.md","url":"/2021/11/21/paper-aGentleIntroductionToGNN-md/","content":"","categories":[],"tags":[]},{"title":"第一讲-图的结构","url":"/2021/10/19/MIT-01-md/","content":" 引言\n​\t图机器学习是我博士期间研究方向，这篇博客会从头到尾详细描述我对于该领域的学习过程。理论部分我会通过学习视频课程和看教材来完成，MIT-CS224W-图机器学习这个分类是我用所看的视频课程的名字命名的，该课程是斯坦福的Jure老师在2021年冬季的课程，该课程也是最好的图机器学习启蒙课程，因此，我会对Jure老师的每一集课程都做一期复现与详解，以帮助自己和读者更好的理解这门课程。本文所有的图片以及公式将大量引用自Jure老师的PPT，在此对老师表示感谢，话不多说，开始第一次课程。\n 一、Motivation for Graph ML\n​\t图是描述与分析包含 关联（relations）或  相互作用（interactions）的实体的通用语言。\n​\t在日常生活中，我们身边许多的数据形式都是图结构。如下图所示，从左到右依次为自然图（natural graph）、基础设施图（infrastructure）、社交网络（social network）、知识图谱（knowledge graph）等诸多领域。\n\n​\t不难看出，当前有两种大的数据类型可以表示为图，首先是网络（network），其次就是图（graph）\n​\tNetworks（Natural Graphs）：自然表示为图\n​\t\t社交网络：社会是70亿人口的集合，那么每个人之间的联系就可以构成一个社交网络。\n​\t\t通讯和交易：例如电子设备，电话通讯，金融交易等等。\n​\t\t生物医学：例如身体中基因或蛋白质之间的相互作用。\n​\t\t脑神经元链接：我们的思维就是由数以亿计的脑神经元链接并相互作用产生的。\n\n​\tGraphs：作为一种表示形式\n​\t\t信息或知识图谱：这些节点都是有组织有关联的。\n​\t\t软件：软件也可以表示为图。\n​\t\t相似性网络（similarity networks）：可以多次将数据点（datapoints）与相似的数据点相连构成相似性网络。\n​\t\t具有关联结构：例如分子间结构，场景图，3D模拟等等。\n\n​\t当我们了解图后，我们就要思考如何利用这些关联结构来进行预测呢？\n","categories":["MIT-CS224W-图机器学习"],"tags":["GNN","MIT","2019"]},{"title":"关于","url":"/about/index.html","content":"Hi！你好！我是来自天津大学的博士研究生小泽，首先十分欢迎你来到我的博客。\n","categories":[],"tags":[]}]